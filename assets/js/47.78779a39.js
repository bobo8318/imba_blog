(window.webpackJsonp=window.webpackJsonp||[]).push([[47],{396:function(s,n,a){"use strict";a.r(n);var e=a(43),r=Object(e.a)({},(function(){var s=this,n=s.$createElement,a=s._self._c||n;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h1",{attrs:{id:"sklearn入门基本知识"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#sklearn入门基本知识"}},[s._v("#")]),s._v(" sklearn入门基本知识")]),s._v(" "),a("ul",[a("li",[s._v("preprocessing.LabelBinarizer 标签二值化")])]),s._v(" "),a("h3",{attrs:{id:"数据标准化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据标准化"}},[s._v("#")]),s._v(" 数据标准化")]),s._v(" "),a("ul",[a("li",[s._v("特征值归化")])]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("from sklearn import preprocessing\nfrom sklearn.datasets.samples_generator import make_classification\n\n\nX, y = make_classification(\n    n_samples=300, n_features=2,\n    n_redundant=0, n_informative=2,\n    random_state=22, n_clusters_per_class=1,\n    scale=100)\n\n#X = preprocessing.scale(X)#-1到1范围\nX = preprocessing.minmax_scale(X,feature_range=(-1,1))\n\n# 1. 基于mean和std的标准化\nscaler = preprocessing.StandardScaler().fit(X)\nX scaler.transform(X)\n\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br")])]),a("h3",{attrs:{id:"数据值拆分"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据值拆分"}},[s._v("#")]),s._v(" 数据值拆分")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v('from sklearn.mode_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n"""\n参数\n---\narrays：样本数组，包含特征向量和标签\n\ntest_size：\n　　float-获得多大比重的测试样本 （默认：0.25）\n　　int - 获得多少个测试样本\n\ntrain_size: 同test_size\n\nrandom_state:\n　　int - 随机种子（种子固定，实验可复现）\n　　\nshuffle - 是否在分割之前对数据进行洗牌（默认True）\n\n返回\n---\n分割后的列表，长度=2*len(arrays),\n　　(train-test split)\n"""\n\n')])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br")])]),a("h3",{attrs:{id:"定义模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#定义模型"}},[s._v("#")]),s._v(" 定义模型")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("# 拟合模型\nmodel.fit(X_train, y_train)\n# 模型预测\nmodel.predict(X_test)\n\n# 获得这个模型的参数\nmodel.get_params()\n# 为模型进行打分\nmodel.score(data_X, data_y) # 线性回归：R square； 分类问题： acc\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("h3",{attrs:{id:"线性回归"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#线性回归"}},[s._v("#")]),s._v(" 线性回归")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v('rom sklearn.linear_model import LinearRegression\n# 定义线性回归模型\nmodel = LinearRegression(fit_intercept=True, normalize=False,\n    copy_X=True, n_jobs=1)\n"""\n参数\n---\n    fit_intercept：是否计算截距。False-模型没有截距\n    normalize： 当fit_intercept设置为False时，该参数将被忽略。 如果为真，则回归前的回归系数X将通过减去平均值并除以l2-范数而归一化。\n     n_jobs：指定线程数\n"""\n')])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br")])]),a("h3",{attrs:{id:"逻辑回归lr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#逻辑回归lr"}},[s._v("#")]),s._v(" 逻辑回归LR")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v('from sklearn.linear_model import LogisticRegression\n# 定义逻辑回归模型\nmodel = LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0,\n    fit_intercept=True, intercept_scaling=1, class_weight=None,\n    random_state=None, solver=’liblinear’, max_iter=100, multi_class=’ovr’,\n    verbose=0, warm_start=False, n_jobs=1)\n\n"""参数\n---\n    penalty：使用指定正则化项（默认：l2）\n    dual: n_samples > n_features取False（默认）\n    C：正则化强度的反，值越小正则化强度越大\n    n_jobs: 指定线程数\n    random_state：随机数生成器\n    fit_intercept: 是否需要常量\n"""\n')])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br")])]),a("h3",{attrs:{id:"朴素贝叶斯算法nb"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#朴素贝叶斯算法nb"}},[s._v("#")]),s._v(" 朴素贝叶斯算法NB")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v('from sklearn import naive_bayes\nmodel = naive_bayes.GaussianNB() # 高斯贝叶斯\nmodel = naive_bayes.MultinomialNB(alpha=1.0, fit_prior=True, class_prior=None)\nmodel = naive_bayes.BernoulliNB(alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None)\n"""\n文本分类问题常用MultinomialNB\n参数\n---\n    alpha：平滑参数\n    fit_prior：是否要学习类的先验概率；false-使用统一的先验概率\n    class_prior: 是否指定类的先验概率；若指定则不能根据参数调整\n    binarize: 二值化的阈值，若为None，则假设输入由二进制向量组成\n"""\n')])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br")])]),a("h3",{attrs:{id:"决策树dt"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#决策树dt"}},[s._v("#")]),s._v(" 决策树DT")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v('rom sklearn import tree\nmodel = tree.DecisionTreeClassifier(criterion=’gini’, max_depth=None,\n    min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n    max_features=None, random_state=None, max_leaf_nodes=None,\n    min_impurity_decrease=0.0, min_impurity_split=None,\n     class_weight=None, presort=False)\n"""参数\n---\n    criterion ：特征选择准则gini/entropy\n    max_depth：树的最大深度，None-尽量下分\n    min_samples_split：分裂内部节点，所需要的最小样本树\n    min_samples_leaf：叶子节点所需要的最小样本数\n    max_features: 寻找最优分割点时的最大特征数\n    max_leaf_nodes：优先增长到最大叶子节点数\n    min_impurity_decrease：如果这种分离导致杂质的减少大于或等于这个值，则节点将被拆分。\n"""\n')])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br")])]),a("h3",{attrs:{id:"支持向量机svm"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#支持向量机svm"}},[s._v("#")]),s._v(" 支持向量机SVM")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v('rom sklearn.svm import SVC\nmodel = SVC(C=1.0, kernel=’rbf’, gamma=’auto’)\n"""参数\n---\n    C：误差项的惩罚参数C\n    gamma: 核相关系数。浮点数，If gamma is ‘auto’ then 1/n_features will be used instead.\n"""\n')])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br")])]),a("h3",{attrs:{id:"k近邻算法knn"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#k近邻算法knn"}},[s._v("#")]),s._v(" k近邻算法KNN")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v('from sklearn import neighbors\n#定义kNN分类模型\nmodel = neighbors.KNeighborsClassifier(n_neighbors=5, n_jobs=1) # 分类\nmodel = neighbors.KNeighborsRegressor(n_neighbors=5, n_jobs=1) # 回归\n"""参数\n---\n    n_neighbors： 使用邻居的数目\n    n_jobs：并行任务数\n"""\n')])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br")])]),a("h3",{attrs:{id:"多层感知机（神经网络）"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#多层感知机（神经网络）"}},[s._v("#")]),s._v(" 多层感知机（神经网络）")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v('rom sklearn.neural_network import MLPClassifier\n# 定义多层感知机分类算法\nmodel = MLPClassifier(activation=\'relu\', solver=\'adam\', alpha=0.0001)\n"""参数\n---\n    hidden_layer_sizes: 元祖\n    activation：激活函数\n    solver ：优化算法{‘lbfgs’, ‘sgd’, ‘adam’}\n    alpha：L2惩罚(正则化项)参数。\n"""\n')])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br")])]),a("h3",{attrs:{id:"模型评估与选择"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#模型评估与选择"}},[s._v("#")]),s._v(" 模型评估与选择")]),s._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[s._v('* 交叉验证  用于特征选择 模型选择\n```\n    from sklearn.model_selection import cross_val_score\n    cross_val_score(model, X, y=None, scoring=None, cv=None, n_jobs=1)\n    """参数\n    ---\n        model：拟合数据的模型\n        cv ： k-fold\n        scoring: 打分参数-‘accuracy’、‘f1’、‘precision’、‘recall’ 、‘roc_auc’、\'neg_log_loss\'等等\n    """\n\n\n\n    import numpy as np\n    from sklearn import datasets\n    from sklearn.cross_validation import train_test_split\n    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.cross_validation import cross_val_score\n\n    # 加载iris数据集\n    iris = datasets.load_iris()\n    # 读取特征\n    X = iris.data\n    # 读取分类标签\n    y = iris.target\n    # 定义分类器\n    knn = KNeighborsClassifier(n_neighbors = 5)\n    # 进行交叉验证数据评估, 数据分为5部分, 每次用一部分作为测试集\n    scores = cross_val_score(knn, X, y, cv = 5, scoring = \'accuracy\')\n    # 输出5次交叉验证的准确率\n    print scores\n\n\n\n\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from sklearn import datasets\n    from sklearn.cross_validation import train_test_split\n    from sklearn.neighbors import KNeighborsClassifier\n    from sklearn.cross_validation import cross_val_score\n\n    # 确定knn中k的取值\n\n    # 加载iris数据集\n    iris = datasets.load_iris()\n    # 读取特征\n    X = iris.data\n    # 读取分类标签\n    y = iris.target\n    # 定义knn中k的取值, 0-10\n    k_range = range(1, 30)\n    # 保存k对应的准确率\n    k_scores = []\n    # 计算每个k取值对应的准确率\n    for k in k_range:\n        # 获得knn分类器\n        knn = KNeighborsClassifier(n_neighbors = k)\n        # 对数据进行交叉验证求准确率\n        scores = cross_val_score(knn, X, y, cv = 10, scoring = \'accuracy\')\n        # 保存交叉验证结果的准确率均值\n        k_scores.append(scores.mean())\n\n    # 绘制k取不同值时的准确率变化图像\n    plt.plot(k_range, k_scores)\n    plt.xlabel(\'K Value in KNN\')\n    plt.ylabel(\'Cross-Validation Mean Accuracy\')\n    plt.show()\n    ```\n\n* 检验曲线\n```\nfrom sklearn.model_selection import validation_curve\ntrain_score, test_score = validation_curve(model, X, y, param_name, param_range, cv=None, scoring=None, n_jobs=1)\n"""参数\n---\n    model:用于fit和predict的对象\n    X, y: 训练集的特征和标签\n    param_name：将被改变的参数的名字\n    param_range： 参数的改变范围\n    cv：k-fold\n\n    返回值\n---\ntrain_score: 训练集得分（array）\ntest_score: 验证集得分（array）\n"""\n```\n')])])]),a("ul",[a("li",[s._v("随机森林")])]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("criterion: ”gini” or “entropy”(default=”gini”)是计算属性的gini(基尼不纯度)还是entropy(信息增益)，来选择最合适的节点。\n\nsplitter: ”best” or “random”(default=”best”)随机选择属性还是选择不纯度最大的属性，建议用默认。\n\nmax_features: 选择最适属性时划分的特征不能超过此值。\n\n当为整数时，即最大特征数；当为小数时，训练集特征数*小数；\n\nif “auto”, then max_features=sqrt(n_features).\n\nIf “sqrt”, thenmax_features=sqrt(n_features).\n\nIf “log2”, thenmax_features=log2(n_features).\n\nIf None, then max_features=n_features.\n\nmax_depth: (default=None)设置树的最大深度，默认为None，这样建树时，会使每一个叶节点只有一个类别，或是达到min_samples_split。\n\nmin_samples_split:根据属性划分节点时，每个划分最少的样本数。\nmin_samples_leaf:叶子节点最少的样本数。\n\nmax_leaf_nodes: (default=None)叶子树的最大样本数。\n\nmin_weight_fraction_leaf: (default=0) 叶子节点所需要的最小权值\n\nverbose:(default=0) 是否显示任务进程\n关于随机森林特有的参数：\nn_estimators=10：决策树的个数，越多越好，但是性能就会越差，至少100左右（具体数字忘记从哪里来的了）可以达到可接受的性能和误差率。\nbootstrap=True：是否有放回的采样。  \noob_score=False：oob（out of band，带外）数据，即：在某次决策树训练中没有被bootstrap选中的数据。多单个模型的参数训练，我们知道可以用cross validation（cv）来进行，但是特别消耗时间，而且对于随机森林这种情况也没有大的必要，所以就用这个数据对决策树模型进行验证，算是一个简单的交叉验证。性能消耗小，但是效果不错。  \n\nn_jobs=1：并行job个数。这个在ensemble算法中非常重要，尤其是bagging（而非boosting，因为boosting的每次迭代之间有影响，所以很难进行并行化），因为可以并行从而提高性能。1=不并行；n：n个并行；-1：CPU有多少core，就启动多少job\n\nwarm_start=False：热启动，决定是否使用上次调用该类的结果然后增加新的。  \n\nclass_weight=None：各个label的权重。  \n\n\n进行预测可以有几种形式：\npredict_proba(x)：给出带有概率值的结果。每个点在所有label的概率和为1.  \n\npredict(x)：直接给出预测结果。内部还是调用的predict_proba()，根据概率的结果看哪个类型的预测值最高就是哪个类型。  \n\npredict_log_proba(x)：和predict_proba基本上一样，只是把结果给做了log()处理。  \n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br"),a("span",{staticClass:"line-number"},[s._v("36")]),a("br"),a("span",{staticClass:"line-number"},[s._v("37")]),a("br"),a("span",{staticClass:"line-number"},[s._v("38")]),a("br"),a("span",{staticClass:"line-number"},[s._v("39")]),a("br"),a("span",{staticClass:"line-number"},[s._v("40")]),a("br"),a("span",{staticClass:"line-number"},[s._v("41")]),a("br"),a("span",{staticClass:"line-number"},[s._v("42")]),a("br"),a("span",{staticClass:"line-number"},[s._v("43")]),a("br"),a("span",{staticClass:"line-number"},[s._v("44")]),a("br")])]),a("h3",{attrs:{id:"保存模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#保存模型"}},[s._v("#")]),s._v(" 保存模型")]),s._v(" "),a("ul",[a("li",[s._v("保存为pickle文件")])]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("import pickle\n\n# 保存模型\nwith open('model.pickle', 'wb') as f:\n    pickle.dump(model, f)\n\n# 读取模型\nwith open('model.pickle', 'rb') as f:\n    model = pickle.load(f)\nmodel.predict(X_test)\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br")])]),a("ul",[a("li",[s._v("sklearn自带方法joblib")])]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("from sklearn.externals import joblib\n\n# 保存模型\njoblib.dump(model, 'model.pickle')\n\n#载入模型\nmodel = joblib.load('model.pickle')\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br")])])])}),[],!1,null,null,null);n.default=r.exports}}]);