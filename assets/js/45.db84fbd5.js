(window.webpackJsonp=window.webpackJsonp||[]).push([[45],{394:function(a,e,t){"use strict";t.r(e);var s=t(43),_=Object(s.a)({},(function(){var a=this,e=a.$createElement,t=a._self._c||e;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h1",{attrs:{id:"opencv"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#opencv"}},[a._v("#")]),a._v(" opencv")]),a._v(" "),t("h3",{attrs:{id:"_1-conda-env-install-opencv"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-conda-env-install-opencv"}},[a._v("#")]),a._v(" 1.conda env install OpenCV")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("clone code")]),a._v(" "),t("blockquote",[t("p",[a._v("git clone https://github.com/mbeyeler/opencv-machine-learning.git")])])]),a._v(" "),t("li",[t("p",[a._v("add conda-Forge")]),a._v(" "),t("blockquote",[t("p",[a._v("conda config --add channels conda-forge")])])]),a._v(" "),t("li",[t("p",[a._v("create env")]),a._v(" "),t("blockquote",[t("p",[a._v("conda install -c https://conda.binstar.org/menpo opencv")])])])]),a._v(" "),t("blockquote",[t("p",[a._v("pip install opencv-python")]),a._v(" "),t("p",[a._v("cv /Users/openui/Documents/gitwb/opencv-machine-learning")]),a._v(" "),t("p",[a._v("conda create -n Python3CV python=3.6 --file requirements.txt")]),a._v(" "),t("p",[a._v("import cv2")]),a._v(" "),t("p",[a._v("print(cv2."),t("strong",[a._v("version")]),a._v(")")]),a._v(" "),t("p",[a._v("http://www.mamicode.com/info-detail-2200546.html?"),t("strong",[a._v("cf_chl_jschl_tk")]),a._v("=28f6631f38b0ca360203696ccbe0afef5d969354-1589977003-0-AU2YD_KbkoaXX4Y7HnHD-vY4ojaR1AkHO6P2Rue48vmLnsc1agi7yXTrhM7a6jMXktoEpyclPTbIEW8f7i3rL6DVE3zK4DcsGatMXJaUIQbm9k_bth9Lqkip6frbeiH7SS3Ry2LI4G57djL_62CwZ5SjTTRvO90Mayg_qCQe6sabz36tTumUKi9vSmLBUNyLgLcJFN0cInW-P1a-0terDmJyKe5pVdXJcgxsOJrZkoshwz7HZV-HBnFTe7jjKqyjQCKszKHsmVutjVi3nfEGaqCq0O32bTdnukIZaFa3PT4h57P7rVQytrXQsdkCVCp0Ug")]),a._v(" "),t("p",[a._v("https://www.cnblogs.com/zuoruining/p/8203162.html")])]),a._v(" "),t("ul",[t("li",[t("p",[a._v("link")]),a._v(" "),t("blockquote",[t("p",[a._v("/Users/openui/opt/anaconda3/envs/python38cv/lib/python3.8/site-packages/cv2/cv2.cpython-38-darwin.so")]),a._v(" "),t("p",[a._v("/usr/local/Cellar/opencv/4.3.0/lib/python3.8/site-packages/cv2/python-3.8/cv2.cpython-38-darwin.so")]),a._v(" "),t("p",[a._v("cd /Users/openui/opt/anaconda3/envs/python38cv/lib/python3.8/site-packages")]),a._v(" "),t("p",[a._v("ln -s /usr/local/Cellar/opencv/4.3.0/lib/python3.8/site-packages/cv2/python-3.8/cv2.cpython-38-darwin.so  cv2.so")])]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/\nconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --set show_channel_urls yes\n\n//C:\\Users\\My\\.condarc\nchannels:\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/\n  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/\nssl_verify: true\nshow_channel_urls: true\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br")])])])]),a._v(" "),t("h3",{attrs:{id:"_2-base"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-base"}},[a._v("#")]),a._v(" 2.base")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("plt")]),a._v(" "),t("blockquote",[t("p",[a._v("import matplotlib.pyplot as plt")]),a._v(" "),t("p",[a._v('plt.style.use("ggplot")')])]),a._v(" "),t("ul",[t("li",[t("p",[a._v("plt.scatter() 散点图")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("matplotlib.pyplot.scatter(x, y, s=None, c=None, marker=None, cmap=None, norm=None, vmin=None, vmax=None, alpha=None, linewidths=None, verts=None, edgecolors=None, *, data=None, **kwargs)\n\n参数的解释：\n\nx，y：表示的是大小为(n,)的数组，也就是我们即将绘制散点图的数据点\n\ns:是一个实数或者是一个数组大小为(n,)，这个是一个可选的参数。\n\nc:表示的是颜色，也是一个可选项。默认是蓝色'b',表示的是标记的颜色，或者可以是一个表示颜色的字符，或者是一个长度为n的表示颜色的序列等等，感觉还没用到过现在不解释了。但是c不可以是一个单独的RGB数字，也不可以是一个RGBA的序列。可以是他们的2维数组（只有一行）。\n\nmarker:表示的是标记的样式，默认的是'o'。\n\ncmap:Colormap实体或者是一个colormap的名字，cmap仅仅当c是一个浮点数数组的时候才使用。如果没有申明就是image.cmap\n\nnorm:Normalize实体来将数据亮度转化到0-1之间，也是只有c是一个浮点数的数组的时候才使用。如果没有申明，就是默认为colors.Normalize。\n\nvmin,vmax:实数，当norm存在的时候忽略。用来进行亮度数据的归一化。\n\nalpha：实数，0-1之间。\n\nlinewidths:也就是标记点的长度。 \n\n示例：\nimport numpy as np\nimport matplotlib.pyplot as plt\n \nnp.random.seed(1)\nx=np.random.rand(10)\ny=np.random.rand(10)\n \ncolors=np.random.rand(10)\narea=(30*np.random.rand(10))**2\n \nplt.scatter(x,y,s=area,c=colors,alpha=0.5)\n\nplt.show()\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br"),t("span",{staticClass:"line-number"},[a._v("9")]),t("br"),t("span",{staticClass:"line-number"},[a._v("10")]),t("br"),t("span",{staticClass:"line-number"},[a._v("11")]),t("br"),t("span",{staticClass:"line-number"},[a._v("12")]),t("br"),t("span",{staticClass:"line-number"},[a._v("13")]),t("br"),t("span",{staticClass:"line-number"},[a._v("14")]),t("br"),t("span",{staticClass:"line-number"},[a._v("15")]),t("br"),t("span",{staticClass:"line-number"},[a._v("16")]),t("br"),t("span",{staticClass:"line-number"},[a._v("17")]),t("br"),t("span",{staticClass:"line-number"},[a._v("18")]),t("br"),t("span",{staticClass:"line-number"},[a._v("19")]),t("br"),t("span",{staticClass:"line-number"},[a._v("20")]),t("br"),t("span",{staticClass:"line-number"},[a._v("21")]),t("br"),t("span",{staticClass:"line-number"},[a._v("22")]),t("br"),t("span",{staticClass:"line-number"},[a._v("23")]),t("br"),t("span",{staticClass:"line-number"},[a._v("24")]),t("br"),t("span",{staticClass:"line-number"},[a._v("25")]),t("br"),t("span",{staticClass:"line-number"},[a._v("26")]),t("br"),t("span",{staticClass:"line-number"},[a._v("27")]),t("br"),t("span",{staticClass:"line-number"},[a._v("28")]),t("br"),t("span",{staticClass:"line-number"},[a._v("29")]),t("br"),t("span",{staticClass:"line-number"},[a._v("30")]),t("br"),t("span",{staticClass:"line-number"},[a._v("31")]),t("br"),t("span",{staticClass:"line-number"},[a._v("32")]),t("br"),t("span",{staticClass:"line-number"},[a._v("33")]),t("br"),t("span",{staticClass:"line-number"},[a._v("34")]),t("br"),t("span",{staticClass:"line-number"},[a._v("35")]),t("br"),t("span",{staticClass:"line-number"},[a._v("36")]),t("br")])])])])])]),a._v(" "),t("h3",{attrs:{id:"_3-数据分析流程"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-数据分析流程"}},[a._v("#")]),a._v(" 3.数据分析流程")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("数据预处理")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("特征选择")]),a._v(" "),t("blockquote",[t("p",[a._v("pandas")]),a._v(" "),t("p",[a._v("x = titanic[['pclass','age','sex']]")]),a._v(" "),t("p",[a._v("y=titanic['survived']")])])]),a._v(" "),t("li",[t("p",[a._v("特征转换")]),a._v(" "),t("blockquote",[t("p",[a._v("from sklearn.feature_extraction import DictVectoriser# 字典特征提取器\nvec = DictVectorizer(sparse=False) "),t("em",[a._v("#sparse=False意思是不产生稀疏矩阵")])]),a._v(" "),t("p",[a._v("data = vec.fit_transform(x_train.to_dict(orient='record'))")]),a._v(" "),t("ol",[t("li",[a._v("将字典数据结构抽和向量化")]),a._v(" "),t("li",[a._v("类别类型特征借助原型特征名称采用0 1 二值方式进行向量化")]),a._v(" "),t("li",[a._v("数值类型特征保持不变")])])])]),a._v(" "),t("li",[t("p",[a._v("特征标准化")]),a._v(" "),t("blockquote",[t("p",[a._v("form sklearn import preprocessing")]),a._v(" "),t("p",[a._v("X_scaled = preprocessing.scale(x)//每行均值等于或接近0")]),a._v(" "),t("p",[a._v("form sklearn.preprocessing  import StandardScaler")]),a._v(" "),t("p",[a._v("ss = StandardScaler()")]),a._v(" "),t("p",[a._v("x_train = ss.fit_transform(x_train)#均值为0 方差为1")]),a._v(" "),t("p",[a._v("x_test = ss.transform(x_test)")])])]),a._v(" "),t("li",[t("p",[a._v("特征归一化 拥有单位范数的过程")]),a._v(" "),t("blockquote",[t("p",[a._v("//L1范数 曼哈顿距离")]),a._v(" "),t("p",[a._v("x_normalized_l1 = preprocessing.normalize(x,norm='l1')")]),a._v(" "),t("p",[a._v("// L2范数 欧氏距离")]),a._v(" "),t("p",[a._v("x_normalized_l2 = preprocessing.normalize(x, norm='l2')")])])]),a._v(" "),t("li",[t("p",[a._v("数据降维 主成分分析PCA")])]),a._v(" "),t("li",[t("p",[a._v("缺失值处理")]),a._v(" "),t("blockquote",[t("p",[a._v("data = data.replace(to_replace='?', value=np.nan)#?替换为标准的缺失值")]),a._v(" "),t("p",[a._v("data = data.dropna(how='any')#丢弃缺失值")]),a._v(" "),t("p",[a._v("x['age'].fillna(x['age'].mean(), inplace=true)#pandas")])])]),a._v(" "),t("li",[t("p",[a._v("数据分割")]),a._v(" "),t("blockquote",[t("p",[a._v("from sklearn import model_selection as modsel")]),a._v(" "),t("p",[a._v("X_train, X_test, y_train, y_test = modsel.train_test_split(boston.data, boston.target, test_size=0.1, random_state=42)")])])]),a._v(" "),t("li",[t("p",[a._v("准确率判断")]),a._v(" "),t("blockquote",[t("p",[a._v("from sklearn.metrics import classification_report\ny_true = [0, 1, 2, 2, 2]\ny_pred = [0, 0, 2, 2, 1]\ntarget_names = ['class 0', 'class 1', 'class 2']\nprint(classification_report(y_true, y_pred, target_names=target_names))")]),a._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",[t("code",[a._v("        precision    recall  f1-score   support\n\nclass 0       0.50      1.00      0.67         1\nclass 1       0.00      0.00      0.00         1\nclass 2       1.00      0.67      0.80         3\n")])])]),t("p",[a._v("avg / total       0.70      0.60      0.61         5")]),a._v(" "),t("p",[a._v("当一个搜索引擎返回30个页面时，只有20页是相关的，而没有返回40个额外的相关页面，其精度为20/30 = 2/3，而其召回率为20/60 = 1/3")])]),a._v(" "),t("ul",[t("li",[a._v("准确性（accuracy）:  分对的样本数除以所有的样本数")]),a._v(" "),t("li",[a._v("召回率（recall）: 结果如何完整")]),a._v(" "),t("li",[a._v("精确率（precision）:  分为正例的示例中实际为正例的比例")]),a._v(" "),t("li",[a._v("f1:  F1 值是精确度和召回率的调和平均值")])])])])]),a._v(" "),t("li",[t("p",[a._v("文本特征表示")]),a._v(" "),t("blockquote",[t("p",[a._v("from sklearn.feature_extraction.text import CountVevtorizer")]),a._v(" "),t("p",[a._v("vec = CountVevtorizer()")]),a._v(" "),t("p",[a._v("x = vec.fit_transform(sample)")]),a._v(" "),t("p",[a._v("x.toarray()# 默认为稀疏矩阵，变为常规矩阵")]),a._v(" "),t("p",[a._v("vec.get_feature_names()")]),a._v(" "),t("p",[a._v("#TF-IDF 通过衡量单词在整个数据中出现的频率来计算权重")]),a._v(" "),t("p",[a._v("from  sklearn.feature_extraction.text import TfidfVevtorizer")]),a._v(" "),t("p",[a._v("vec = TfidfVevtorizer()")])])]),a._v(" "),t("li",[t("p",[a._v("图像表示")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("RGB色彩空间编码图像")]),a._v(" "),t("blockquote",[t("p",[a._v("import cv2")]),a._v(" "),t("p",[a._v("import matplotlib.pyplot as plt")]),a._v(" "),t("p",[a._v("img = cv2.imread('data/lena.jpg')")]),a._v(" "),t("p",[a._v("img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)")]),a._v(" "),t("p",[a._v("plt.figure(figsize=(12,6))")]),a._v(" "),t("p",[a._v("plt.subplot(121)")]),a._v(" "),t("p",[a._v("plt.imshow(img)")]),a._v(" "),t("p",[a._v("img.subplot(122)")]),a._v(" "),t("p",[a._v("plt.imshow(img_rgb)")]),a._v(" "),t("p",[a._v("plt.show()")])])]),a._v(" "),t("li",[t("p",[a._v("HSV & HLS")]),a._v(" "),t("blockquote",[t("p",[a._v("cv2.COLOR_BGR2HSV")]),a._v(" "),t("p",[a._v("cv2.COLOR_BGR2HLS")]),a._v(" "),t("p",[a._v("cv2.COLOR_BGR2LAB")]),a._v(" "),t("p",[a._v("cv2.COLOR_BGR2YUV")])])]),a._v(" "),t("li",[t("p",[a._v("角点检测")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("Harris角点检测:仅可以处理灰度图像")]),a._v(" "),t("blockquote",[t("p",[a._v("img_gray = cv2.cvtColo(img_bgr, cv2.COLOR_BGR2GRAY)")]),a._v(" "),t("p",[a._v("corners = cv2.cornerHarris(img_gray, 2, 3, 0.04)# (灰度图像, 角点检测的像素领域大小, 边缘检测的孔径参数, harris检测器自有参数)")]),a._v(" "),t("p",[a._v("plt.imshow(corners, cmap='gray')")])])]),a._v(" "),t("li",[t("p",[a._v("Shi-Tomasi角点检测")]),a._v(" "),t("blockquote",[t("p",[a._v("cv2.goodFearuresToTrack()")])])]),a._v(" "),t("li",[t("p",[a._v("尺度不变特征变换")]),a._v(" "),t("blockquote",[t("p",[a._v("sift = cv2.xfeatures2d.SIFT_create()")]),a._v(" "),t("p",[a._v("kp = sift.detect(img_bgr) #检测")]),a._v(" "),t("p",[a._v("import numpy as np")]),a._v(" "),t("p",[a._v("img_kp = np.zeros_like(img_bgr)")]),a._v(" "),t("p",[a._v("img_kp = cv2.drawKeypoints(img_bgr, kp, img_kp, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)")]),a._v(" "),t("p",[a._v("plt.imshow(imgkp)")]),a._v(" "),t("p",[a._v("#计算特征描述")]),a._v(" "),t("p",[a._v("kp, des = sift.compute(img_bgr, kp)")]),a._v(" "),t("p",[a._v("kp2, des2 = sift.detectAndCompute(img_bgr, None)")]),a._v(" "),t("p",[a._v("#判断两个方法的结果是否相同")]),a._v(" "),t("p",[a._v("np.allclose(des, des2)")])])]),a._v(" "),t("li",[t("p",[a._v("加强健壮特征:SURF")]),a._v(" "),t("blockquote",[t("p",[a._v("surf = cv2.xfeatures2d.SURF_create()")]),a._v(" "),t("p",[a._v("kp = surf.detect(img_bgr)")]),a._v(" "),t("p",[a._v("cv2.ORB 免费的替代方案")])])])])])])])]),a._v(" "),t("h3",{attrs:{id:"_4-决策树"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-决策树"}},[a._v("#")]),a._v(" 4. 决策树")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("data pre")]),a._v(" "),t("blockquote",[t("p",[a._v("from sklearn.feature_extraction import DictVectorizer # One-Hot 编码")]),a._v(" "),t("p",[a._v("vec = DictVectorizer(sparse=False) #sparse=False意思是不产生稀疏矩阵")]),a._v(" "),t("p",[a._v("data_pre = vec.fit_transform(data)")]),a._v(" "),t("h1",{attrs:{id:""}},[t("a",{staticClass:"header-anchor",attrs:{href:"#"}},[a._v("#")])]),a._v(" "),t("p",[a._v("data_pre = np.array(data_pre, dtype=np.float32)")])])]),a._v(" "),t("li",[t("p",[a._v("split data")]),a._v(" "),t("blockquote",[t("p",[a._v("import numy as np")]),a._v(" "),t("p",[a._v("from sklearn.model_selection as ms")]),a._v(" "),t("p",[a._v("x_train, x_test, y_train, y_test = ms.train_test_split(data_pre, target, test_size=5, random_state = 42)")])])]),a._v(" "),t("li",[t("p",[a._v("create decide tree")]),a._v(" "),t("blockquote",[t("p",[a._v("import cv2")]),a._v(" "),t("p",[a._v("dtree = cv2.ml.dtree_create()")])])]),a._v(" "),t("li",[t("p",[a._v("train and predict")]),a._v(" "),t("blockquote",[t("p",[a._v("dtree.train(x_train, cv2.ml.ROW_SAMPLE, y_train) #  cv2.ml.ROW_SAMPLE / cv2.ml.COL_SAMPLE")]),a._v(" "),t("p",[a._v("y_pred = dtree.predict(x_test)")])])]),a._v(" "),t("li",[t("p",[a._v("test")]),a._v(" "),t("blockquote",[t("p",[a._v("from sklearn import metrics")]),a._v(" "),t("p",[a._v("metrics.accuracy_score(y_test, y_pred)")])])]),a._v(" "),t("li",[t("p",[a._v("show tree")]),a._v(" "),t("blockquote",[t("p",[a._v("from sklearn import tree # 使用sklearn构造决策树")]),a._v(" "),t("p",[a._v("dtc = tree.DecisionTreeClassifier() #空的决策树")]),a._v(" "),t("p",[a._v("dtc.fit(x_train, y_train)")]),a._v(" "),t("p",[a._v("dtc.score(x_test, y_test)")]),a._v(" "),t("p",[a._v("conda install graphviz")]),a._v(" "),t("p",[a._v("#导出决策树")]),a._v(" "),t("p",[a._v('with open("tree.dot", "w"):')]),a._v(" "),t("p",[a._v("​\tf = tree.export_graphviz(clf, out_file=f)")])])]),a._v(" "),t("li",[t("p",[a._v("决策规则")]),a._v(" "),t("blockquote",[t("p",[a._v("dtc = tree.DecisionTreeClassifier(criterion='entropy ')")])]),a._v(" "),t("ul",[t("li",[a._v("gini 基尼")]),a._v(" "),t("li",[a._v("entropy 信息熵")])])]),a._v(" "),t("li",[t("p",[a._v("决策树复杂度")]),a._v(" "),t("blockquote",[t("p",[a._v("DecisionTreeClassifier参数")]),a._v(" "),t("p",[a._v("max_depth")]),a._v(" "),t("p",[a._v("max_leaf_nodes")]),a._v(" "),t("p",[a._v("min_samples_split 设置一节点中的最小数据点来持续分割")])])]),a._v(" "),t("li",[t("p",[a._v("决策树进行回归")]),a._v(" "),t("blockquote",[t("p",[a._v("tree.DecisionTreeRegressor()")])])])]),a._v(" "),t("h3",{attrs:{id:"_5-svm"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-svm"}},[a._v("#")]),a._v(" 5.SVM")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("生成模拟数据")]),a._v(" "),t("blockquote",[t("p",[a._v("x,y = datasets.make_classification(n_samples=100, n_features=2, n_redundant=0, n_classes=2, random_state=7816)")]),a._v(" "),t("p",[a._v("plt.scatter(x[:, 0], x[:, 1], c=y, s=100)")]),a._v(" "),t("p",[a._v("plt.xlabel('x values')")]),a._v(" "),t("p",[a._v("plt.ylabel('y values')")]),a._v(" "),t("p",[a._v("plt.show()")])])]),a._v(" "),t("li",[t("p",[a._v("数据预处理")]),a._v(" "),t("blockquote",[t("p",[a._v("x = x.astype(np.float32)")]),a._v(" "),t("p",[a._v("y = y*2 - 1 # -1 或 1")]),a._v(" "),t("p",[a._v("x_train, x_test, y_train, y_test = ms.train_test_split(x, y, test_size=0.2, random_state=42)")])])])]),a._v(" "),t("h3",{attrs:{id:"_6-贝叶斯"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-贝叶斯"}},[a._v("#")]),a._v(" 6.贝叶斯")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("使用sklearn")]),a._v(" "),t("blockquote",[t("p",[a._v("from sklearn import naive_bayes")]),a._v(" "),t("p",[a._v("model_naive = naive_bayes.GaussianNB()")]),a._v(" "),t("p",[a._v("model_naive.fit(x_train, y_train)")])])])]),a._v(" "),t("h3",{attrs:{id:"_7-kmeans"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7-kmeans"}},[a._v("#")]),a._v(" 7.kmeans")]),a._v(" "),t("ul",[t("li",[t("p",[a._v("一些基础知识")]),a._v(" "),t("blockquote",[t("p",[a._v("reshape(-1,3) # -1表示由计算机自己下决定行数，行数不直接指定")]),a._v(" "),t("p",[a._v("np.array([X[labels==i].mean(axis=0) for i in range(n_clusters)])")])])])])])}),[],!1,null,null,null);e.default=_.exports}}]);